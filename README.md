# chaos4455

# nlp-model-downloader ğŸš€âœ¨

## Seu Assistente Inteligente para Preparar o Ambiente NLP! ğŸ¤–ğŸ”§

[![Python Version](https://img.shields.io/badge/Python-3.8+-blue.svg?style=for-the-badge&logo=python)](https://python.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/Status-Ativo%20âœ…-success?style=for-the-badge)](https://github.com/chaos4455/nlp-toolkit-downloader/)
[![Autor](https://img.shields.io/badge/Criado%20por-Elias%20Andrade%20(chaos4455)-informational?style=for-the-badge)](https://github.com/chaos4455)

<!-- Badges dos Modelos/Dados -->
<p align="center">
  <img src="https://img.shields.io/badge/Modelo-BERT%20(base/large)-blue?style=flat-square&logo=google" alt="BERT Badge"/>
  <img src="https://img.shields.io/badge/Modelo-GPT--2%20(base/medium)-green?style=flat-square&logo=openai" alt="GPT-2 Badge"/>
  <img src="https://img.shields.io/badge/Modelo-Whisper%20(s/m/l--v3)-purple?style=flat-square&logo=openai" alt="Whisper Badge"/>
  <img src="https://img.shields.io/badge/Dados-NLTK%20Essentials-red?style=flat-square" alt="NLTK Badge"/>
  <img src="https://img.shields.io/badge/Embeddings-Word2Vec%20%26%20GloVe-orange?style=flat-square" alt="Embeddings Badge"/>
</p>

---

## ğŸ¯ O que Ã© isso?

![c20f2ade-ba12-49a7-9f1d-5b95026fad51](https://github.com/user-attachments/assets/6313c7ab-7992-4d6a-b1a9-9204c18202c9)


Cansado de baixar manualmente cada modelo e pacote de dados para seus projetos de Processamento de Linguagem Natural (NLP)? ğŸ˜© Perder tempo configurando tudo repetidamente?

O **NLP Toolkit Downloader** Ã© um script Python robusto e altamente visual projetado para automatizar completamente o download e a configuraÃ§Ã£o inicial dos modelos e conjuntos de dados NLP mais populares. Ele transforma um processo potencialmente tedioso em uma execuÃ§Ã£o simples e informativa, direto no seu console!  console colorido, detalhado e cheio de emojis! ğŸ¨ğŸ“Š

Criado por [Elias Andrade (chaos4455)](https://github.com/chaos4455), este script Ã© ideal para pesquisadores, estudantes e desenvolvedores que precisam de um ambiente NLP pronto para usar rapidamente.

## âœ¨ Funcionalidades Principais

Este script nÃ£o Ã© apenas um downloader, Ã© um assistente de configuraÃ§Ã£o inteligente:

*   âœ… **Download Automatizado:** Baixa mÃºltiplos modelos e dados de fontes confiÃ¡veis (Hugging Face ğŸ¤—, NLTK, Gensim) com um Ãºnico comando.
*   ğŸ¨ **Console Rico e Colorido:** Utiliza `colorama` para fornecer feedback visual claro, com cores diferentes para status (sucesso, erro, aviso, cache), etapas e informaÃ§Ãµes.
*   ğŸ“Š **Feedback Detalhado em Tempo Real:** Exibe mensagens passo a passo sobre o que estÃ¡ acontecendo, desde a verificaÃ§Ã£o de dependÃªncias atÃ© o download e testes bÃ¡sicos.
*   â³ **Barras de Progresso:** Integra-se com as barras de progresso das bibliotecas subjacentes (`transformers`, `gensim`) para downloads maiores, mostrando o andamento real.
*   ğŸ’¾ **VerificaÃ§Ã£o Inteligente de Cache:** Detecta se os modelos/dados jÃ¡ existem localmente para evitar downloads desnecessÃ¡rios, economizando tempo e banda.
*   ğŸ§  **Suporte a Diversos Modelos e Dados:** Configurado para baixar uma variedade de ferramentas essenciais (veja a lista abaixo).
*   ğŸ§ª **Testes BÃ¡sicos PÃ³s-Download:** Realiza verificaÃ§Ãµes simples apÃ³s o download para garantir que os modelos foram carregados corretamente.
*   âŒ **Tratamento de Erros:** Captura e reporta erros de forma clara (ex: dependÃªncias ausentes, problemas de rede, modelos nÃ£o encontrados).
*   â±ï¸ **Resumo Final:** Apresenta um sumÃ¡rio ao final da execuÃ§Ã£o, mostrando o nÃºmero de tarefas bem-sucedidas, falhas e o tempo total decorrido.

## ğŸ“¦ Modelos e Dados Baixados

O script estÃ¡ configurado por padrÃ£o para baixar os seguintes recursos:

| Ãcone | Tipo        | Modelos/Dados EspecÃ­ficos                                     | Fonte Principal      | Badge Exemplo                                                                                                     |
| :---: | :---------- | :------------------------------------------------------------ | :------------------- | :---------------------------------------------------------------------------------------------------------------- |
| ğŸ§     | **BERT**    | `bert-base-uncased`, `bert-large-uncased`                   | Hugging Face ğŸ¤—      | ![](https://img.shields.io/badge/BERT-blue?style=flat&logo=google)                                                |
| ğŸ§     | **GPT-2**   | `gpt2`, `gpt2-medium`                                         | Hugging Face ğŸ¤—      | ![](https://img.shields.io/badge/GPT--2-green?style=flat&logo=openai)                                             |
| ğŸ¤    | **Whisper** | `whisper-small`, `whisper-medium`, `whisper-large-v3`       | Hugging Face ğŸ¤—      | ![](https://img.shields.io/badge/Whisper-purple?style=flat&logo=openai)                                           |
| ğŸ“š    | **NLTK Data** | `punkt`, `stopwords`, `wordnet`, `averaged_perceptron_tagger` | NLTK Project         | ![](https://img.shields.io/badge/NLTK-red?style=flat)                                                             |
| ğŸ“„    | **Embeddings**| `word2vec-google-news-300`, `glove-wiki-gigaword-100`         | Gensim Downloader    | ![](https://img.shields.io/badge/Embeddings-orange?style=flat)                                                    |

*ObservaÃ§Ã£o: O download desses modelos, especialmente os maiores (BERT Large, GPT-2 Medium, Whisper Large), pode consumir vÃ¡rios gigabytes de espaÃ§o em disco e levar um tempo considerÃ¡vel dependendo da sua conexÃ£o com a internet.* ğŸŒâ³

## ğŸ› ï¸ PrÃ©-requisitos

Antes de executar o script, vocÃª precisarÃ¡ ter:

## âš™ï¸ InstalaÃ§Ã£o das DependÃªncias

Precisa instalar as bibliotecas Python necessÃ¡rias. VocÃª pode fazer isso facilmente usando `pip`.

Abra seu terminal ou prompt de comando e execute o seguinte comando:

```bash
pip install colorama transformers torch nltk gensim tqdm requests huggingface_hub
```

1.  **Python:** VersÃ£o 3.8 ou superior recomendada.
    [![Python Version](https://img.shields.io/badge/Python-3.8+-blue.svg?style=flat&logo=python)](https://python.org)
2.  **Pip:** O gerenciador de pacotes do Python (geralmente vem junto com o Python).
3.  **Bibliotecas Python:** As seguintes bibliotecas sÃ£o necessÃ¡rias e serÃ£o usadas pelo script:
    *   `colorama`: Para a saÃ­da colorida no console.
    *   `transformers`: Para baixar e carregar modelos BERT, GPT-2 e Whisper do Hugging Face Hub.
    *   `torch`: Backend de Deep Learning para os modelos do `transformers` (PyTorch).
        *   *Nota:* A instalaÃ§Ã£o do PyTorch pode variar dependendo do seu sistema operacional e se vocÃª tem uma GPU compatÃ­vel com CUDA. Consulte o [site oficial do PyTorch](https://pytorch.org/) para as instruÃ§Ãµes corretas.
    *   `nltk`: Para baixar dados linguÃ­sticos (tokenizers, stopwords, etc.).
    *   `gensim`: Para baixar modelos de Word Embeddings prÃ©-treinados (Word2Vec, GloVe).
    *   `tqdm`: Usado internamente por `transformers` e `gensim` para exibir barras de progresso.
    *   `requests`: DependÃªncia comum para operaÃ§Ãµes de rede.
    *   `huggingface_hub`: Para interagir com o Hugging Face Hub e realizar verificaÃ§Ãµes de cache mais avanÃ§adas.

    VocÃª pode instalar todas de uma vez (exceto talvez `torch`, veja a nota acima) com:
    ```bash
    pip install colorama transformers nltk gensim tqdm requests huggingface_hub torch
    ```
    [![Dependencies](https://img.shields.io/badge/Libs-Transformers%20%7C%20PyTorch%20%7C%20NLTK%20%7C%20Gensim%20%7C%20HF--Hub-critical?style=flat)](requirements.txt)
    *(Nota: Considere criar um arquivo `requirements.txt` para facilitar a instalaÃ§Ã£o)*

## ğŸš€ Como Usar

1.  **Clone o RepositÃ³rio:**
    ```bash
    git clone https://github.com/chaos4455/nlp-toolkit-downloader.git
    cd nlp-toolkit-downloader
    ```
    Ou baixe o cÃ³digo ZIP diretamente do GitHub.

2.  **Instale as DependÃªncias:**
    Certifique-se de ter todas as bibliotecas listadas na seÃ§Ã£o de PrÃ©-requisitos instaladas. Use o comando pip fornecido acima. Lembre-se da instalaÃ§Ã£o potencialmente especÃ­fica do PyTorch!

3.  **Execute o Script:**
    Abra seu terminal ou prompt de comando, navegue atÃ© a pasta do projeto e execute:
    ```bash
    python download_models_advanced.py
    ```
    *(Substitua `download_models_advanced.py` pelo nome real do arquivo, se diferente)*

4.  **Acompanhe o Processo:**
    Sente-se e observe o console! O script mostrarÃ¡ cada etapa, verificaÃ§Ãµes de cache, downloads (com barras de progresso quando aplicÃ¡vel), testes e, finalmente, um resumo. ğŸ‰

## ğŸ–¥ï¸ Exemplo de SaÃ­da no Console (Conceitual)

VocÃª verÃ¡ algo parecido com isto (mas muito mais detalhado e colorido!):

## ğŸ–¥ï¸ Exemplo de SaÃ­da no Console (Conceitual)

VocÃª verÃ¡ algo parecido com isto (mas muito mais detalhado e colorido!):

```text
================================================================================
ğŸš€ INICIANDO PIPELINE AVANÃ‡ADO DE DOWNLOAD DE MODELOS E DADOS ğŸš€
================================================================================

â¡ï¸ Verificando DependÃªncias Essenciais
  âœ… Todas as dependÃªncias principais encontradas.

â„¹ï¸ Processando Tarefa 1/10: Modelo BERT Base (Uncased) ğŸ“¦
â¡ï¸ Download BERT Base: bert-base-uncased
  ğŸ” Verificando cache local para bert-base-uncased...
  ğŸ’¾ bert-base-uncased parece estar no cache.
  â†ªï¸ Carregando Tokenizer...
    âœ… Tokenizer carregado com sucesso.
    â±ï¸ Tempo de carregamento (Tokenizer): 0.15s
    ğŸ’¾ Tokenizer provavelmente carregado do cache (tempo baixo).
  â†ªï¸ Carregando Modelo Principal...
    âœ… Modelo principal carregado com sucesso.
    â±ï¸ Tempo de carregamento (Modelo): 0.80s
    ğŸ’¾ Modelo principal provavelmente carregado do cache (tempo baixo).
  ğŸ§ª Realizando teste bÃ¡sico de carregamento para bert-base-uncased...
    ğŸ§ª Teste de pipeline 'feature-extraction' OK.
    ğŸ§ª Teste bÃ¡sico para bert-base-uncased passou.
  âœ… BERT Base 'bert-base-uncased' pronto para uso!
â±ï¸ Tarefa 1 concluÃ­da com sucesso em 1.20s.
------------------------------
â„¹ï¸ Processando Tarefa 2/10: Modelo BERT Large (Uncased) ğŸ“¦
â¡ï¸ Download BERT Large: bert-large-uncased
  ğŸ” Verificando cache local para bert-large-uncased...
  ğŸŒ bert-large-uncased nÃ£o encontrado ou incompleto no cache. Preparando para download/verificaÃ§Ã£o.
  â†ªï¸ Carregando Tokenizer...
    âœ… Tokenizer carregado com sucesso.
    â±ï¸ Tempo de carregamento (Tokenizer): 5.50s
  â†ªï¸ Carregando Modelo Principal...
    Downloading pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [01:30<00:00, 15.8MB/s]
    âœ… Modelo principal carregado com sucesso.
    â±ï¸ Tempo de carregamento (Modelo): 95.30s
  ğŸ§ª Realizando teste bÃ¡sico de carregamento para bert-large-uncased...
    ... (testes) ...
    ğŸ§ª Teste bÃ¡sico para bert-large-uncased passou.
  âœ… BERT Large 'bert-large-uncased' pronto para uso!
â±ï¸ Tarefa 2 concluÃ­da com sucesso em 102.10s.
------------------------------
... (outras tarefas) ...

================================================================================
âœ¨ RESUMO FINAL DO PIPELINE âœ¨
================================================================================
ğŸ“Š Tarefas totais planejadas: 10
âœ… Tarefas concluÃ­das com sucesso: 10
âŒ Tarefas que falharam: 0
  Nenhuma tarefa falhou.
â±ï¸ DuraÃ§Ã£o total do pipeline: 350.50 segundos (5.8 minutos)
================================================================================
âœ… Pipeline concluÃ­do com sucesso! Todos os modelos/dados solicitados devem estar prontos.

```

## âš™ï¸ CustomizaÃ§Ã£o

Quer baixar outros modelos ou remover alguns da lista? Ã‰ fÃ¡cil!

1.  Abra o arquivo Python do script (ex: `download_models_advanced.py`).
2.  Localize a lista `tasks` dentro da funÃ§Ã£o `main()`.
3.  Cada item na lista Ã© uma tupla definindo uma tarefa: `(funÃ§Ã£o_download, [lista_de_argumentos], "DescriÃ§Ã£o")`.
4.  **Para adicionar um modelo:** Copie uma linha existente (ex: de BERT ou GPT-2), altere o `model_id` (ex: `"distilbert-base-uncased"`) e a descriÃ§Ã£o. Certifique-se de usar a `model_loader` correta (ex: `AutoModel` para DistilBERT).
5.  **Para remover um modelo:** Simplesmente comente (adicione `#` no inÃ­cio) ou delete a linha correspondente da lista `tasks`.
6.  **Para alterar dados NLTK:** Modifique a lista de pacotes no argumento da tarefa `download_nltk_data`.

Salve o arquivo e execute o script novamente.

##ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Se vocÃª tiver sugestÃµes para melhorar o script, adicionar mais funcionalidades ou encontrar bugs, sinta-se Ã  vontade para:

1.  Abrir uma **Issue** para discutir a mudanÃ§a.
2.  Fazer um **Fork** do repositÃ³rio.
3.  Criar uma nova **Branch** para sua feature (`git checkout -b feature/AmazingFeature`).
4.  Fazer **Commit** das suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`).
5.  Fazer **Push** para a Branch (`git push origin feature/AmazingFeature`).
6.  Abrir um **Pull Request**.

##ğŸ“œ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais informaÃ§Ãµes.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](https://opensource.org/licenses/MIT)

##ğŸ‘¨â€ğŸ’» Autor

*   **Elias Andrade (chaos4455)**
*   GitHub: [@chaos4455](https://github.com/chaos4455)

---

Espero que este script facilite seus projetos de NLP! ğŸ˜Š

