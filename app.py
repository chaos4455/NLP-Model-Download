# -*- coding: utf-8 -*-
import os
import sys
import time
import re # Importado para a corre√ß√£o do NLTK find
import nltk
import gensim.downloader
import colorama
from colorama import Fore, Style, Back
import logging
from tqdm import tqdm # Usaremos tqdm diretamente para NLTK se necess√°rio

# --- Depend√™ncias Opcionais (Importa√ß√µes Seguras) ---
try:
    from transformers import (
        AutoModel, AutoTokenizer,
        WhisperProcessor, WhisperForConditionalGeneration,
        AutoModelForCausalLM, # Para GPT-2
        pipeline # Para um teste r√°pido p√≥s-download
    )
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    from huggingface_hub.constants import HUGGINGFACE_HUB_CACHE
    from huggingface_hub.file_download import repo_folder_name # Removido hf_hub_download (n√£o usado diretamente)
    from huggingface_hub import model_info # Removido list_models (n√£o usado)
    HUGGINGFACE_HUB_AVAILABLE = True
except ImportError:
    HUGGINGFACE_HUB_AVAILABLE = False

# --- Configura√ß√£o Inicial ---
# Desabilita logs INFO excessivos que poluem o console
logging.getLogger("filelock").setLevel(logging.WARNING)
logging.getLogger("transformers.utils.hub").setLevel(logging.WARNING) # Menos verboso
logging.getLogger('nltk.downloader').setLevel(logging.WARNING)
logging.getLogger("urllib3.connectionpool").setLevel(logging.WARNING) # Download HTTP logs

# Inicializa Colorama
colorama.init(autoreset=True)

# --- Constantes de Emojis e Cores ---
ICON_START = "üöÄ"
ICON_STEP = "‚û°Ô∏è"
ICON_SUBSTEP = "‚Ü™Ô∏è"
ICON_DOWNLOAD = "üì•"
ICON_UPLOAD = "üì§" # Placeholder, n√£o usado para download
ICON_INFO = "‚ÑπÔ∏è"
ICON_SUCCESS = "‚úÖ"
ICON_ERROR = "‚ùå"
ICON_WARN = "‚ö†Ô∏è"
ICON_CACHE = "üíæ"
ICON_MODEL = "üì¶"
ICON_BRAIN = "üß†" # BERT, GPT
ICON_MIC = "üé§" # Whisper
ICON_BOOK = "üìö" # NLTK
ICON_WORD = "üìÑ" # Word2Vec
ICON_FINISH = "‚ú®"
ICON_CHECK = "üîç"
ICON_NETWORK = "üåê"
ICON_CLOCK = "‚è±Ô∏è"
ICON_CONFIG = "‚öôÔ∏è"
ICON_TEST = "üß™"
ICON_SKIP = "üö´" # √çcone para tarefas puladas

COLOR_TITLE = Fore.MAGENTA + Style.BRIGHT
COLOR_STEP = Fore.CYAN + Style.BRIGHT
COLOR_SUBSTEP = Fore.CYAN
COLOR_INFO = Fore.BLUE
COLOR_SUCCESS = Fore.GREEN + Style.BRIGHT
COLOR_ERROR = Fore.RED + Style.BRIGHT
COLOR_WARN = Fore.YELLOW + Style.BRIGHT
COLOR_PROGRESS = Fore.YELLOW
COLOR_DETAIL = Fore.WHITE
COLOR_CACHE = Fore.LIGHTBLUE_EX
COLOR_NETWORK = Fore.LIGHTMAGENTA_EX
COLOR_TEST = Fore.LIGHTGREEN_EX
COLOR_SKIP = Fore.LIGHTBLACK_EX # Cor para tarefas puladas

# --- CONFIGURA√á√ÉO DE DOWNLOAD ---
# Edite os valores abaixo para True ou False para controlar o que ser√° baixado.
# True = Baixar este item.
# False = Pular este item.
# ----------------------------------
DOWNLOAD_CONFIG = {
    # Modelos Transformers (Hugging Face)
    "Modelo BERT Base (Uncased)": True,
    "Modelo BERT Large (Uncased)": True,
    "Modelo GPT-2 (Base)": True,
    "Modelo GPT-2 Medium": True,
    "Modelo Whisper Small": True,
    "Modelo Whisper Medium": False,      # <<< Definido como False
    "Modelo Whisper Large v3": False,    # <<< Definido como False

    # Dados NLTK
    "Dados Essenciais NLTK": True,

    # Modelos Gensim (Word Embeddings)
    "Modelo Word2Vec Google News": True,
    "Modelo GloVe Wikipedia (100d)": True,

    # Adicione futuras tarefas aqui com True/False
    # Exemplo: "Meu Novo Modelo X": False,
}
# ----------------------------------

# --- Fun√ß√µes Auxiliares de Log ---
def print_color(text, color=COLOR_DETAIL, style="", end="\n", **kwargs):
    """Imprime texto colorido, resetando automaticamente."""
    print(f"{style}{color}{text}{Style.RESET_ALL}", end=end, **kwargs)
    sys.stdout.flush() # Garante visibilidade imediata

def log_header(message):
    """Loga um cabe√ßalho principal."""
    print_color("=" * 80, COLOR_TITLE)
    print_color(f" {ICON_START} {message} {ICON_START} ".center(80, "="), COLOR_TITLE + Style.BRIGHT)
    print_color("=" * 80, COLOR_TITLE)
    print()

def log_step(message):
    """Loga o in√≠cio de um passo principal."""
    print_color(f"\n{ICON_STEP} {message}", COLOR_STEP)
    print_color("-" * (len(message) + 4), COLOR_STEP)

def log_substep(message, indent=1):
    """Loga um subpasso dentro de um passo principal."""
    prefix = "  " * indent
    print_color(f"{prefix}{ICON_SUBSTEP} {message}", COLOR_SUBSTEP)

def log_info(message, indent=1, icon=ICON_INFO):
    """Loga uma informa√ß√£o geral."""
    prefix = "  " * indent
    print_color(f"{prefix}{icon} {message}", COLOR_INFO)

def log_detail(message, indent=2, icon=""):
    """Loga um detalhe da opera√ß√£o."""
    prefix = "  " * indent
    icon_str = f"{icon} " if icon else ""
    print_color(f"{prefix}{icon_str}{message}", COLOR_DETAIL)

def log_download_progress(message, indent=1):
    """Loga uma mensagem relacionada ao download."""
    prefix = "  " * indent
    print_color(f"{prefix}{ICON_DOWNLOAD} {message}", COLOR_PROGRESS)

def log_cache_check(message, indent=1):
    """Loga mensagem de verifica√ß√£o de cache."""
    prefix = "  " * indent
    print_color(f"{prefix}{ICON_CHECK} {message}", COLOR_CACHE)

def log_cache_hit(message, indent=1):
    """Loga mensagem de cache hit."""
    prefix = "  " * indent
    print_color(f"{prefix}{ICON_CACHE} {message}", COLOR_CACHE + Style.BRIGHT)

def log_network_op(message, indent=1):
     """Loga mensagem de opera√ß√£o de rede."""
     prefix = "  " * indent
     print_color(f"{prefix}{ICON_NETWORK} {message}", COLOR_NETWORK)

def log_success(message, indent=1):
    """Loga uma mensagem de sucesso."""
    prefix = "  " * indent
    print_color(f"{prefix}{ICON_SUCCESS} {message}", COLOR_SUCCESS)

def log_error(message, indent=1, error_details=""):
    """Loga uma mensagem de erro."""
    prefix = "  " * indent
    print_color(f"{prefix}{ICON_ERROR} {message}", COLOR_ERROR)
    if error_details:
        # Tenta decodificar detalhes do erro se forem bytes (comum em exce√ß√µes)
        if isinstance(error_details, bytes):
            try:
                error_details = error_details.decode('utf-8', errors='replace')
            except Exception:
                error_details = str(error_details) # Fallback
        elif not isinstance(error_details, str):
             error_details = str(error_details) # Garante que seja string

        # Limita o tamanho dos detalhes do erro para n√£o poluir demais
        max_len = 500
        details_short = (error_details[:max_len] + '...') if len(error_details) > max_len else error_details
        print_color(f"{prefix}  Detalhes: {details_short.replace(os.linesep, ' ')}", Fore.RED) # Remove newlines para log conciso
    sys.stderr.flush()

def log_warning(message, indent=1):
    """Loga uma mensagem de aviso."""
    prefix = "  " * indent
    print_color(f"{prefix}{ICON_WARN} {message}", COLOR_WARN)

def log_test(message, indent=1):
    """Loga uma mensagem de teste/valida√ß√£o."""
    prefix = "  " * indent
    print_color(f"{prefix}{ICON_TEST} {message}", COLOR_TEST)

def log_skip(message, indent=1):
    """Loga uma mensagem de tarefa pulada."""
    prefix = "  " * indent
    print_color(f"{prefix}{ICON_SKIP} {message}", COLOR_SKIP)

# --- Fun√ß√µes de Verifica√ß√£o e Download ---

def check_dependencies():
    """Verifica se as depend√™ncias principais est√£o instaladas."""
    log_step("Verificando Depend√™ncias Essenciais")
    all_ok = True
    if not TRANSFORMERS_AVAILABLE:
        log_error("Biblioteca 'transformers' n√£o encontrada.", 1)
        log_info("Instale com: pip install transformers[torch]", 2) # Sugere com torch
        all_ok = False
    if not TORCH_AVAILABLE:
        log_error("Biblioteca 'torch' (PyTorch) n√£o encontrada.", 1)
        log_info("Instale em https://pytorch.org/ ou com: pip install torch", 2)
        log_warning("Transformers pode n√£o funcionar sem PyTorch (ou TensorFlow).", 1)
        # N√£o definimos all_ok = False, pode funcionar com TF, mas √© um aviso importante
    if not HUGGINGFACE_HUB_AVAILABLE:
        log_error("Biblioteca 'huggingface_hub' n√£o encontrada.", 1)
        log_info("Instale com: pip install huggingface_hub", 2)
        all_ok = False # Verifica√ß√£o de cache avan√ßada falhar√°

    try:
        import nltk
    except ImportError:
        log_error("Biblioteca 'nltk' n√£o encontrada.", 1)
        log_info("Instale com: pip install nltk", 2)
        all_ok = False

    try:
        import gensim
    except ImportError:
        log_error("Biblioteca 'gensim' n√£o encontrada.", 1)
        log_info("Instale com: pip install gensim", 2)
        all_ok = False

    if not all_ok:
        log_error("Depend√™ncias essenciais faltando. Por favor, instale-as e tente novamente.", 0)
        sys.exit(1) # Termina se depend√™ncias cr√≠ticas faltam
    else:
        log_success("Todas as depend√™ncias principais encontradas.", 1)
        time.sleep(1)


def check_transformer_cache_advanced(model_id):
    """Verifica heuristicamente se um modelo transformers parece estar no cache."""
    if not HUGGINGFACE_HUB_AVAILABLE:
        # log_warning("Biblioteca 'huggingface_hub' n√£o dispon√≠vel, pulando verifica√ß√£o de cache avan√ßada.", 2)
        return False # Se n√£o tem a lib, n√£o tem como checar
    try:
        # Caminho esperado para o diret√≥rio do modelo no cache padr√£o do Hugging Face
        resolved_cache_dir = HUGGINGFACE_HUB_CACHE
        # Usa a fun√ß√£o oficial para obter o nome da pasta, mais robusto
        model_cache_path = os.path.join(resolved_cache_dir, repo_folder_name(repo_id=model_id, repo_type="model"))

        # Verifica se o diret√≥rio existe
        if not os.path.isdir(model_cache_path):
             return False

        # Verifica se arquivos essenciais existem (heur√≠stica mais forte)
        # Ex: config.json E algum arquivo de peso (.bin, .safetensors)
        has_config = any(f.lower() == 'config.json' for f in os.listdir(model_cache_path))
        has_model_file = any(f.lower().endswith(('.bin', '.safetensors')) for f in os.listdir(model_cache_path))

        # Pode adicionar checagem de tokenizer.json se necess√°rio
        # has_tokenizer = any(f.lower() == 'tokenizer.json' for f in os.listdir(model_cache_path))

        # Considera em cache se os arquivos principais estiverem presentes
        return has_config and has_model_file
    except Exception as e:
        log_warning(f"N√£o foi poss√≠vel verificar o cache para {model_id}: {e}", 2)
        return False # Assume n√£o estar em cache se a verifica√ß√£o falhar


def download_transformer_model(model_id, model_loader, tokenizer_loader=AutoTokenizer, processor_loader=None, model_type="Modelo Gen√©rico"):
    """
    Fun√ß√£o gen√©rica para baixar/carregar modelos, tokenizers e processors
    do Hugging Face com verifica√ß√£o de cache e logging.
    """
    icon = ICON_BRAIN if "BERT" in model_type or "GPT" in model_type else ICON_MIC if "Whisper" in model_type else ICON_MODEL
    log_step(f"Tarefa: {model_type}: {model_id} {icon}")

    if not TRANSFORMERS_AVAILABLE:
         log_error(f"Biblioteca 'transformers' n√£o dispon√≠vel para {model_id}.", 1)
         return False
    # Aviso se PyTorch n√£o estiver dispon√≠vel, mas continua (pode usar TF)
    if not TORCH_AVAILABLE:
        log_warning(f"PyTorch n√£o encontrado. Tentando carregar {model_id} (pode requerer TensorFlow).", 1)

    model = None
    tokenizer_or_processor = None
    loaded_from_cache = {"model": False, "tokenizer_processor": False} # Rastreia cache separadamente

    # 1. Checagem de Cache (Vis√£o Geral)
    log_cache_check(f"Verificando cache local para {model_id}...", 1)
    is_cached_heuristic = check_transformer_cache_advanced(model_id)
    if is_cached_heuristic:
        log_cache_hit(f"{model_id} parece estar no cache (verifica√ß√£o heur√≠stica).", 1)
        # Marcamos como potencialmente em cache, ser√° confirmado pelo tempo de carregamento
        loaded_from_cache["model"] = True
        loaded_from_cache["tokenizer_processor"] = True
    else:
        log_network_op(f"{model_id} n√£o encontrado ou incompleto no cache. Preparando para download/verifica√ß√£o.", 1)
        if HUGGINGFACE_HUB_AVAILABLE:
            try:
                info = model_info(model_id)
                # siblings = [f.rfilename for f in info.siblings if not f.rfilename.endswith(('.gitattributes', '.gitignore'))] # Mais espec√≠fico
                num_files = len([f for f in info.siblings if not f.rfilename.startswith('.')]) # Conta arquivos n√£o ocultos
                log_detail(f"Arquivos esperados no reposit√≥rio: ~{num_files}", 2, icon=ICON_CONFIG)
            except Exception as e:
                log_warning(f"N√£o foi poss√≠vel obter informa√ß√µes do Hub para {model_id}: {e}", 2)

    # 2. Download/Load Tokenizer ou Processor
    loader = processor_loader if processor_loader else tokenizer_loader
    loader_name = "Processor" if processor_loader else "Tokenizer"
    if loader:
        log_substep(f"Carregando {loader_name} ({model_id})...", 1)
        try:
            start_time = time.time()
            tokenizer_or_processor = loader.from_pretrained(model_id) # cache_dir pode ser especificado se necess√°rio
            duration = time.time() - start_time
            log_detail(f"{loader_name} carregado com sucesso.", 2, icon=ICON_SUCCESS)
            log_detail(f"Tempo de carregamento ({loader_name}): {duration:.2f}s", 2, icon=ICON_CLOCK)
            # Refina a checagem de cache com base no tempo de carregamento
            if duration < 0.5 and loaded_from_cache["tokenizer_processor"]: # Carregou r√°pido E heur√≠stica disse cache
                 log_cache_hit(f"{loader_name} confirmado no cache (tempo baixo).", 2)
            elif duration >= 0.5 and not loaded_from_cache["tokenizer_processor"]: # Carregou devagar E heur√≠stica disse n√£o-cache (prov√°vel download)
                 log_download_progress(f"{loader_name} provavelmente baixado ou verificado.", 2)
            # Se a heur√≠stica e o tempo discordarem, o tempo √© mais confi√°vel
            elif duration < 0.5 and not loaded_from_cache["tokenizer_processor"]:
                 log_cache_hit(f"{loader_name} carregado rapidamente, provavelmente estava em cache apesar da heur√≠stica inicial.", 2)
                 loaded_from_cache["tokenizer_processor"] = True # Corrige estado do cache

        except Exception as e:
            log_error(f"Falha ao carregar {loader_name} para {model_id}", 1, error_details=e)
            return False # Falha cr√≠tica se o tokenizer/processor n√£o carregar
        time.sleep(0.1) # Pausa para legibilidade

    # 3. Download/Load Modelo Principal
    log_substep(f"Carregando Modelo Principal ({model_id})...", 1)
    try:
        start_time = time.time()
        if not loaded_from_cache["model"]:
             log_download_progress("Iniciando download/verifica√ß√£o do modelo (pode levar tempo)...", 2)
        # A m√°gica acontece aqui: from_pretrained faz o download se necess√°rio
        model = model_loader.from_pretrained(model_id)
        duration = time.time() - start_time
        log_detail("Modelo principal carregado com sucesso.", 2, icon=ICON_SUCCESS)
        log_detail(f"Tempo de carregamento (Modelo): {duration:.2f}s", 2, icon=ICON_CLOCK)

        # Refina checagem de cache para o modelo
        if duration < 1.0 and loaded_from_cache["model"]:
             log_cache_hit("Modelo principal confirmado no cache (tempo baixo).", 2)
        elif duration >= 1.0 and not loaded_from_cache["model"]:
             log_download_progress("Modelo principal provavelmente baixado ou verificado.", 2)
        elif duration < 1.0 and not loaded_from_cache["model"]:
             log_cache_hit("Modelo principal carregado rapidamente, provavelmente estava em cache.", 2)
             loaded_from_cache["model"] = True # Corrige estado

        # 4. Teste B√°sico (Opcional, mas √∫til)
        log_test(f"Realizando teste b√°sico de carregamento para {model_id}...", 1)
        try:
            _ = model.config # Acessa a configura√ß√£o (teste m√≠nimo)
            if hasattr(model, 'device'):
                log_detail(f"Modelo carregado no dispositivo: {model.device}", 2)
            else:
                 log_detail("Teste de acesso √† configura√ß√£o OK.", 2)

            # Teste funcional com pipeline (se dispon√≠vel e aplic√°vel)
            if TRANSFORMERS_AVAILABLE and pipeline is not None and tokenizer_or_processor is not None:
                 task = None
                 if "BERT" in model_type: task = 'feature-extraction'
                 elif "GPT-2" in model_type: task = 'text-generation'
                 # Whisper precisa de 'automatic-speech-recognition' e input de √°udio (pulamos teste funcional)

                 if task:
                     log_test(f"Tentando pipeline '{task}'...", 2)
                     pipe = pipeline(task, model=model, tokenizer=tokenizer_or_processor, device=-1) # For√ßa CPU para teste
                     if task == 'feature-extraction': _ = pipe("Teste.")
                     elif task == 'text-generation': _ = pipe("Ol√°,", max_length=10)
                     log_test(f"Teste de pipeline '{task}' OK.", 2)
                 elif "Whisper" in model_type:
                      log_test("Teste de pipeline Whisper pulado (requer input de √°udio).", 2)

            else:
                log_test("Teste de pipeline pulado (transformers.pipeline ou tokenizer/processor n√£o dispon√≠vel).", 2)

            log_test(f"Teste b√°sico para {model_id} conclu√≠do.", 1)

        except Exception as e:
            log_warning(f"Teste b√°sico para {model_id} falhou ou n√£o p√¥de ser executado completamente: {e}", 1)
            # N√£o retorna False aqui, o download principal funcionou.

        log_success(f"{model_type} '{model_id}' pronto para uso!", 0) # Sucesso no n√≠vel do passo
        return True

    except Exception as e:
        log_error(f"Falha ao carregar o Modelo Principal para {model_id}", 1, error_details=e)
        return False


def download_nltk_data(packages):
    """
    Baixa pacotes de dados do NLTK com verifica√ß√£o de cache e logging.
    'packages' deve ser uma lista de strings (nomes dos pacotes).
    """
    log_step(f"Tarefa: Download de Dados NLTK {ICON_BOOK}")
    if not isinstance(packages, list) or not all(isinstance(p, str) for p in packages):
         log_error(f"Argumento inv√°lido para download_nltk_data: esperado uma lista de strings, recebeu {type(packages)}.", 1)
         return False
    log_info(f"Pacotes solicitados: {', '.join(packages)}", 1)

    try:
        import nltk
        # Configura o downloader do NLTK para ser um pouco menos verboso por padr√£o
        # nltk.downloader.Downloader(quiet=True) # Pode esconder demais, vamos deixar o padr√£o por enquanto
    except ImportError:
        log_error("Biblioteca 'nltk' n√£o encontrada.", 1)
        return False

    missing_packages = []
    for pkg_id in packages:
        if not isinstance(pkg_id, str): # Sanity check interno
             log_error(f"Item inv√°lido na lista de pacotes NLTK: {pkg_id} (tipo {type(pkg_id)}). Pulando.", 2)
             continue

        log_cache_check(f"Verificando pacote NLTK: '{pkg_id}'...", 2)
        found = False
        try:
            # nltk.data.find agora √© mais robusto e busca em v√°rios locais por padr√£o
            nltk.data.find(pkg_id)
            log_cache_hit(f"Pacote '{pkg_id}' encontrado.", 2)
            found = True
        except LookupError:
            log_warning(f"Pacote NLTK '{pkg_id}' n√£o encontrado localmente.", 2)
            missing_packages.append(pkg_id)
        except Exception as e:
            log_error(f"Erro ao verificar o pacote NLTK '{pkg_id}': {e}", 2)
            # Considera como faltando se houver erro na verifica√ß√£o
            if pkg_id not in missing_packages:
                missing_packages.append(pkg_id)


    if not missing_packages:
        log_success("Todos os pacotes NLTK solicitados j√° est√£o presentes!", 1)
        return True

    log_network_op(f"Iniciando download para pacotes NLTK faltantes: {', '.join(missing_packages)}", 1)

    download_successful = False
    try:
        print_color("-" * 40, COLOR_NETWORK) # Separador visual
        # quiet=False para ver o output detalhado do NLTK
        # O NLTK lida com a barra de progresso internamente se o TQDM estiver instalado
        nltk.download(missing_packages, quiet=False)
        # Assume sucesso se n√£o lan√ßar exce√ß√£o, mas verificaremos novamente
        download_successful = True
        print_color("-" * 40, COLOR_NETWORK) # Separador visual
    except Exception as e:
        # Erros durante o download (rede, permiss√£o, etc.)
        log_error("Ocorreu um erro durante o download do NLTK.", 1, error_details=str(e))
        # Tentamos verificar mesmo assim, talvez alguns tenham baixado
        # return False # N√£o retorna imediatamente, verifica o que foi baixado

    # Verifica novamente ap√≥s a tentativa de download (crucial!)
    final_missing = []
    all_verified = True
    log_info("Verificando pacotes ap√≥s tentativa de download...", 1)
    for pkg_id in missing_packages:
         try:
             nltk.data.find(pkg_id) # Verifica novamente
             log_detail(f"'{pkg_id}' verificado com sucesso ap√≥s download.", 2, icon=ICON_SUCCESS)
         except LookupError:
             log_error(f"Pacote '{pkg_id}' ainda n√£o encontrado ap√≥s tentativa de download.", 2)
             final_missing.append(pkg_id)
             all_verified = False
         except Exception as e:
             log_error(f"Erro ao re-verificar o pacote NLTK '{pkg_id}': {e}", 2)
             final_missing.append(pkg_id)
             all_verified = False


    if all_verified and download_successful:
         log_success("Download e verifica√ß√£o dos pacotes NLTK conclu√≠do!", 0) # Sucesso no n√≠vel do passo
         return True
    else:
         if final_missing:
            log_error(f"Falha ao baixar ou verificar os seguintes pacotes NLTK: {', '.join(final_missing)}.", 0) # Erro no n√≠vel do passo
         else:
             log_error("Download NLTK conclu√≠do com erros (ver logs acima).", 0)
         log_info("Verifique sua conex√£o ou permiss√µes de escrita no diret√≥rio de dados do NLTK.", 1)
         return False


def download_word2vec(model_name="word2vec-google-news-300"):
    """
    Baixa um modelo Word2Vec/GloVe pr√©-treinado usando gensim.downloader.
    """
    log_step(f"Tarefa: Download Word Embedding: {model_name} {ICON_WORD}")

    try:
        import gensim.downloader
    except ImportError:
        log_error("Biblioteca 'gensim' n√£o encontrada.", 1)
        return False

    log_info(f"Solicitando '{model_name}' ao Gensim Downloader.", 1)
    log_network_op("Gensim verificar√° o cache e iniciar√° o download se necess√°rio.", 1)
    log_detail("Gensim pode mostrar barras de progresso abaixo.", 2)

    wv = None # Inicializa wv
    try:
        start_time = time.time()
        print_color("-" * 40, COLOR_NETWORK) # Separador visual
        # A chamada load() faz o download e/ou carrega do cache
        wv = gensim.downloader.load(model_name)
        print_color("-" * 40, COLOR_NETWORK) # Separador visual
        duration = time.time() - start_time

        # Verifica se carregou algo
        if wv is None:
            log_error(f"Gensim retornou 'None' para '{model_name}', indicando falha no carregamento.", 1)
            return False

        log_success(f"Modelo '{model_name}' baixado/carregado com sucesso!", 1)
        log_detail(f"Tempo total (download/load): {duration:.2f}s", 2, icon=ICON_CLOCK)

        try:
            # Tenta obter detalhes e testar
            if hasattr(wv, 'key_to_index') and hasattr(wv, 'vector_size'):
                 vocab_size = len(wv.key_to_index)
                 vector_dim = wv.vector_size
                 log_detail(f"Tamanho do vocabul√°rio: {vocab_size}", 2, icon=ICON_CONFIG)
                 log_detail(f"Dimens√£o dos vetores: {vector_dim}", 2, icon=ICON_CONFIG)

                 log_test(f"Realizando teste b√°sico com '{model_name}'...", 1)
                 # Tenta encontrar palavras comuns para teste
                 test_words = ['computer', 'house', 'king', 'data']
                 word_found = None
                 for word in test_words:
                     if word in wv:
                         word_found = word
                         break
                 # Se nenhuma comum for encontrada, pega uma aleat√≥ria (menos ideal)
                 if not word_found and wv.key_to_index:
                     word_found = list(wv.key_to_index.keys())[0]

                 if word_found:
                     _ = wv[word_found] # Acessa o vetor
                     log_test(f"Vetor para '{word_found}' acessado.", 2)
                     if hasattr(wv, 'most_similar'):
                         similars = wv.most_similar(word_found, topn=3)
                         log_test(f"Palavras similares a '{word_found}': {[(w, f'{s:.2f}') for w, s in similars]}", 2)
                     log_test("Teste b√°sico de acesso passou.", 1)
                 else:
                     log_warning(f"N√£o foi poss√≠vel encontrar palavras comuns para teste em '{model_name}'.", 1)
            else:
                log_warning(f"O objeto carregado para '{model_name}' n√£o parece ser um modelo KeyedVectors padr√£o.", 1)

        except Exception as e:
             log_warning(f"N√£o foi poss√≠vel obter detalhes completos ou testar o modelo '{model_name}': {e}", 1)

        log_success(f"Word Embedding '{model_name}' pronto para uso!", 0) # Sucesso no n√≠vel do passo
        return True

    except ValueError as e:
         # Gensim levanta ValueError para modelo n√£o encontrado no cat√°logo
         if "not found" in str(e).lower():
              log_error(f"Modelo '{model_name}' n√£o encontrado no cat√°logo do Gensim.", 1)
              try:
                  available_models = list(gensim.downloader.info()['models'].keys())
                  log_info(f"Modelos dispon√≠veis (exemplo): {available_models[:10]}...", 2)
              except Exception:
                  log_info("N√£o foi poss√≠vel listar modelos dispon√≠veis do Gensim.", 2)
         else:
              log_error(f"Erro ao baixar/carregar '{model_name}'", 1, error_details=e)
         return False
    except Exception as e:
        # Captura outros erros (rede, disco, formato inesperado, etc.)
        log_error(f"Falha inesperada ao baixar/carregar '{model_name}'", 1, error_details=e)
        return False


# --- Pipeline Principal ---
def main():
    """Executa o pipeline de download configur√°vel."""
    log_header("PIPELINE DE DOWNLOAD DE MODELOS E DADOS DE NLP")
    start_pipeline_time = time.time()

    # 1. Verificar depend√™ncias primeiro
    check_dependencies()

    # 2. Definir todas as tarefas poss√≠veis
    # Formato: (fun√ß√£o_download, [lista_de_argumentos], "Descri√ß√£o da Tarefa")
    # A "Descri√ß√£o da Tarefa" DEVE corresponder EXATAMENTE a uma chave em DOWNLOAD_CONFIG
    all_possible_tasks = [
        # Transformers
        (download_transformer_model, ["bert-base-uncased", AutoModel, AutoTokenizer, None, "BERT Base"], "Modelo BERT Base (Uncased)"),
        (download_transformer_model, ["bert-large-uncased", AutoModel, AutoTokenizer, None, "BERT Large"], "Modelo BERT Large (Uncased)"),
        (download_transformer_model, ["gpt2", AutoModelForCausalLM, AutoTokenizer, None, "GPT-2"], "Modelo GPT-2 (Base)"),
        (download_transformer_model, ["gpt2-medium", AutoModelForCausalLM, AutoTokenizer, None, "GPT-2 Medium"], "Modelo GPT-2 Medium"),
        (download_transformer_model, ["openai/whisper-small", WhisperForConditionalGeneration, None, WhisperProcessor, "Whisper Small"], "Modelo Whisper Small"),
        (download_transformer_model, ["openai/whisper-medium", WhisperForConditionalGeneration, None, WhisperProcessor, "Whisper Medium"], "Modelo Whisper Medium"),
        (download_transformer_model, ["openai/whisper-large-v3", WhisperForConditionalGeneration, None, WhisperProcessor, "Whisper Large v3"], "Modelo Whisper Large v3"),

        # NLTK Data (Argumento CORRIGIDO para ser uma lista de strings)
        (download_nltk_data, ["punkt", "stopwords", "wordnet", "averaged_perceptron_tagger"], "Dados Essenciais NLTK"),

        # Gensim Word Embeddings
        (download_word2vec, ["word2vec-google-news-300"], "Modelo Word2Vec Google News"),
        (download_word2vec, ["glove-wiki-gigaword-100"], "Modelo GloVe Wikipedia (100d)"),

        # Adicione a defini√ß√£o de novas tarefas potenciais aqui
        # Exemplo: (minha_funcao_download, [arg1, arg2], "Meu Novo Modelo X"),
    ]

    # 3. Filtrar Tarefas com base na Configura√ß√£o
    tasks_to_run = []
    skipped_tasks_count = 0
    log_step(f"Configurando Tarefas de Download {ICON_CONFIG}")
    log_info(f"Verificando {len(all_possible_tasks)} tarefas poss√≠veis contra a configura√ß√£o...", 1)
    time.sleep(0.5) # Pausa para leitura

    configured_task_names = set(DOWNLOAD_CONFIG.keys())
    defined_task_names = {desc for _, _, desc in all_possible_tasks}

    # Avisar sobre tarefas definidas no c√≥digo mas n√£o na configura√ß√£o
    missing_in_config = defined_task_names - configured_task_names
    if missing_in_config:
        log_warning(f"As seguintes tarefas est√£o definidas no c√≥digo mas FALTAM em DOWNLOAD_CONFIG:", 1)
        for task_name in missing_in_config:
             log_detail(f"- {task_name} (ser√° pulada por padr√£o)", 2)

    # Avisar sobre tarefas na configura√ß√£o mas n√£o definidas no c√≥digo (typos?)
    missing_in_code = configured_task_names - defined_task_names
    if missing_in_code:
        log_warning(f"As seguintes tarefas est√£o em DOWNLOAD_CONFIG mas N√ÉO est√£o definidas na lista 'all_possible_tasks':", 1)
        for task_name in missing_in_code:
             log_detail(f"- {task_name} (ser√° ignorada)", 2)


    for task_definition in all_possible_tasks:
        func, args, desc = task_definition
        # Pega o valor da configura√ß√£o; default √© False se a chave n√£o existir
        should_run = DOWNLOAD_CONFIG.get(desc, False)

        if should_run:
            tasks_to_run.append(task_definition)
            log_info(f"Habilitado: {desc}", 2, icon=ICON_SUCCESS)
        else:
            skipped_tasks_count += 1
            # Loga apenas se a tarefa estava definida no c√≥digo
            if desc in defined_task_names:
                reason = "(definido como False)" if desc in DOWNLOAD_CONFIG else "(n√£o encontrado ou False em DOWNLOAD_CONFIG)"
                log_skip(f"Pulando: {desc} {reason}", 2)

    if not tasks_to_run:
         log_warning("\nNenhuma tarefa habilitada para execu√ß√£o na configura√ß√£o.", 0)
         log_info("Edite o dicion√°rio DOWNLOAD_CONFIG no topo do script para habilitar tarefas.", 0)
         # Conclui o pipeline mesmo sem tarefas para executar
    else:
        log_info(f"\n{len(tasks_to_run)} tarefas ser√£o executadas.", 1)
        if skipped_tasks_count > 0:
            log_info(f"{skipped_tasks_count} tarefas foram puladas conforme configura√ß√£o.", 1, icon=ICON_SKIP)

    time.sleep(1.5) # Pausa antes de come√ßar a execu√ß√£o

    # 4. Execu√ß√£o das Tarefas Selecionadas
    results = {
        "success": 0,
        "failed": 0,
        "skipped": skipped_tasks_count,
        "total_attempted": len(tasks_to_run),
        "failed_tasks": []
    }

    for i, (func, args, desc) in enumerate(tasks_to_run):
        # Mensagem movida para dentro das fun√ß√µes de download (log_step)
        # log_info(f"Executando Tarefa {i+1}/{results['total_attempted']}: {desc}", indent=0)
        task_start_time = time.time()
        success = False
        try:
            # Chama a fun√ß√£o de download real (ex: download_transformer_model)
            success = func(*args)
        except Exception as e:
             # Captura erro inesperado na *chamada* da fun√ß√£o (improv√°vel, mas seguro)
             log_error(f"Erro catastr√≥fico ao tentar iniciar a tarefa '{desc}'", 0, error_details=e)
             import traceback
             log_detail(f"Traceback: {traceback.format_exc()}", 1) # Imprime stack trace
             success = False # Garante que seja marcado como falha

        task_duration = time.time() - task_start_time

        if success:
            results["success"] += 1
            # Log de sucesso principal j√° √© feito dentro da fun√ß√£o de download
            # Adicionamos apenas a dura√ß√£o aqui no resumo da tarefa
            log_detail(f"Tarefa '{desc}' conclu√≠da em {task_duration:.2f}s.", 0, icon=ICON_CLOCK)
        else:
            results["failed"] += 1
            results["failed_tasks"].append(desc)
            # Log de erro principal j√° deve ter ocorrido dentro da fun√ß√£o
            log_detail(f"Tarefa '{desc}' falhou (ver logs acima). Dura√ß√£o: {task_duration:.2f}s.", 0, icon=ICON_CLOCK)

        # Pausa entre tarefas para melhor legibilidade e evitar sobrecarga de rede/disco
        if i < results["total_attempted"] - 1:
             log_detail("-" * 40, indent=0) # Separador visual entre tarefas
             time.sleep(1.5)

    # 5. Resumo Final
    end_pipeline_time = time.time()
    pipeline_duration = end_pipeline_time - start_pipeline_time

    print_color("\n" + "=" * 80, COLOR_TITLE)
    print_color(f" {ICON_FINISH} RESUMO FINAL DO PIPELINE {ICON_FINISH} ".center(80, "="), COLOR_TITLE + Style.BRIGHT)
    print_color("=" * 80, COLOR_TITLE)

    log_info(f"Total de tarefas poss√≠veis definidas no script: {len(all_possible_tasks)}", 0, icon="üìä")
    log_info(f"Tarefas puladas conforme configura√ß√£o: {results['skipped']}", 0, icon=ICON_SKIP)
    log_info(f"Tarefas que tentaram ser executadas: {results['total_attempted']}", 0, icon=ICON_CONFIG) # √çcone de engrenagem
    log_success(f"Tarefas conclu√≠das com sucesso: {results['success']}", 0)

    if results['failed'] > 0:
        log_error(f"Tarefas que falharam: {results['failed']}", 0)
        for failed_task in results['failed_tasks']:
            log_detail(f"- {failed_task}", 1, icon=ICON_ERROR)
    else:
        # Apenas diz que n√£o falhou se tentamos executar alguma tarefa
        if results['total_attempted'] > 0:
             log_detail("Nenhuma tarefa executada falhou.", 0)
        elif results['skipped'] == len(all_possible_tasks): # Se todas foram puladas
             log_info("Nenhuma tarefa foi executada (todas puladas ou desabilitadas).", 0)


    log_info(f"Dura√ß√£o total do pipeline: {pipeline_duration:.2f} segundos ({pipeline_duration/60:.1f} minutos)", 0, icon=ICON_CLOCK)
    print_color("=" * 80, COLOR_TITLE)

    # Mensagem final baseada nos resultados
    if results["failed"] == 0 and results['success'] > 0:
        print_color(f"{ICON_SUCCESS} Pipeline conclu√≠do com sucesso! Os itens selecionados devem estar prontos.", COLOR_SUCCESS)
    elif results["failed"] > 0:
        print_color(f"{ICON_WARN} Pipeline conclu√≠do com {results['failed']} falha(s). Verifique os logs de erro acima.", COLOR_WARN)
    elif results['total_attempted'] == 0:
         print_color(f"{ICON_INFO} Nenhuma tarefa foi executada. Verifique a configura√ß√£o 'DOWNLOAD_CONFIG'.", COLOR_INFO)
    else: # Caso de 0 falhas e 0 sucessos (ex: todas tentaram mas falharam antes de come√ßar?) - Improv√°vel
         print_color(f"{ICON_INFO} Pipeline conclu√≠do, mas sem sucessos ou falhas registradas. Verifique os logs.", COLOR_INFO)


    colorama.deinit() # Desliga o colorama no final

# --- Ponto de Entrada ---
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print_color(f"\n\n{ICON_WARN} Opera√ß√£o interrompida pelo usu√°rio (Ctrl+C).", COLOR_WARN)
        colorama.deinit() # Garante a desinicializa√ß√£o
        sys.exit(130) # C√≥digo de sa√≠da comum para interrup√ß√£o
    except SystemExit as e:
        # Permite sa√≠das normais (ex: falha de depend√™ncia em check_dependencies)
        if e.code != 0: # S√≥ loga se for uma sa√≠da de erro expl√≠cita
             print_color(f"\n{ICON_ERROR} Script terminado com c√≥digo de sa√≠da: {e.code}", COLOR_ERROR)
        colorama.deinit()
        sys.exit(e.code)
    except Exception as e:
        # Captura qualquer outra exce√ß√£o n√£o tratada no n√≠vel superior
        print_color(f"\n\n{ICON_ERROR} Erro Inesperado e N√£o Tratado no Pipeline Principal!", COLOR_ERROR + Style.BRIGHT)
        import traceback
        # Imprime o traceback completo para depura√ß√£o
        print_color(traceback.format_exc(), Fore.RED)
        colorama.deinit()
        sys.exit(1) # C√≥digo de erro gen√©rico
